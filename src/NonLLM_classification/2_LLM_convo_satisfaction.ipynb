{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.width', 10000)\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVO level preprocessing\n",
    "# Read in data, get the conversation turns, and overall average rating\n",
    "def process_conversation_data_debug(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    conversations = []\n",
    "    conversation_id = 1\n",
    "    conversation_text = []\n",
    "    avg_rating = []\n",
    "\n",
    "    for idx, line in enumerate(lines):\n",
    "        line = line.strip()\n",
    "        if not line:  # Skip empty lines\n",
    "            continue\n",
    "\n",
    "        # print(f\"Processing Line {idx + 1}\")  # Debug: Print every line being processed\n",
    "        parts = line.split(\"\\t\")\n",
    "        \n",
    "        if line.startswith(\"USER\") or line.startswith(\"SYSTEM\"):\n",
    "            if len(parts) >= 2:\n",
    "                speaker = parts[0]\n",
    "                text = parts[1]\n",
    "                cleaned_text = text.replace(\"\\n\", \"\")\n",
    "                # print(f\"{speaker}{cleaned_text}\")\n",
    "                conversation_text.append(f\"{speaker} {cleaned_text}\")\n",
    "\n",
    "                # print(f\"{speaker} {text}\")\n",
    "\n",
    "        if line.startswith(\"USER\\tOVERALL\"):\n",
    "            # print(f\"Processing OVERALL Line {idx + 1}\")  # Debug for OVERALL lines\n",
    "            overall_ratings = list(map(int, parts[3].split(\",\")))\n",
    "            convo_avg = round(sum(overall_ratings) / len(overall_ratings),2)\n",
    "            \n",
    "            # Append conversation\n",
    "            conversations.append({\n",
    "                \"conv_id\": conversation_id,\n",
    "                \"conv_text\": \"\\n\".join(conversation_text),\n",
    "                \"average_rating\": convo_avg\n",
    "            })\n",
    "            conversation_id += 1\n",
    "            conversation_text = []\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(conversations)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conv_id</th>\n",
       "      <th>conv_text</th>\n",
       "      <th>average_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>USER I'm looking for a cheap restaurant in the...</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>USER Hi, I will be traveling to Cambridge and ...</td>\n",
       "      <td>2.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>USER I am looking for a cheap two star hotel i...</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>USER Can you recommend a good restaurant in th...</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>USER I need a place to stay in Cambridge that ...</td>\n",
       "      <td>3.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>996</td>\n",
       "      <td>USER I'm looking for a cheap hotel.\\nSYSTEM al...</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>997</td>\n",
       "      <td>USER I'm looking for a Lebanese restaurant tha...</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>998</td>\n",
       "      <td>USER I wanted to visit a place called Center, ...</td>\n",
       "      <td>3.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>999</td>\n",
       "      <td>USER Could you help me find a restaurant that'...</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1000</td>\n",
       "      <td>USER I want to find a guesthouse to stay at in...</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     conv_id                                          conv_text  average_rating\n",
       "0          1  USER I'm looking for a cheap restaurant in the...            2.75\n",
       "1          2  USER Hi, I will be traveling to Cambridge and ...            2.67\n",
       "2          3  USER I am looking for a cheap two star hotel i...            3.00\n",
       "3          4  USER Can you recommend a good restaurant in th...            3.50\n",
       "4          5  USER I need a place to stay in Cambridge that ...            3.33\n",
       "..       ...                                                ...             ...\n",
       "995      996  USER I'm looking for a cheap hotel.\\nSYSTEM al...            2.75\n",
       "996      997  USER I'm looking for a Lebanese restaurant tha...            3.00\n",
       "997      998  USER I wanted to visit a place called Center, ...            3.67\n",
       "998      999  USER Could you help me find a restaurant that'...            3.50\n",
       "999     1000  USER I want to find a guesthouse to stay at in...            2.00\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '../data/raw/MWOZ.txt'\n",
    "conversation_df = process_conversation_data_debug(file_path)\n",
    "conversation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     conv_id                                          conv_text  average_rating  token_count\n",
      "0          1  USER I'm looking for a cheap restaurant in the...            2.75          173\n",
      "1          2  USER Hi, I will be traveling to Cambridge and ...            2.67          468\n",
      "2          3  USER I am looking for a cheap two star hotel i...            3.00          313\n",
      "3          4  USER Can you recommend a good restaurant in th...            3.50          219\n",
      "4          5  USER I need a place to stay in Cambridge that ...            3.33          334\n",
      "..       ...                                                ...             ...          ...\n",
      "995      996  USER I'm looking for a cheap hotel.\\nSYSTEM al...            2.75          336\n",
      "996      997  USER I'm looking for a Lebanese restaurant tha...            3.00          343\n",
      "997      998  USER I wanted to visit a place called Center, ...            3.67          570\n",
      "998      999  USER Could you help me find a restaurant that'...            3.50          287\n",
      "999     1000  USER I want to find a guesthouse to stay at in...            2.00          162\n",
      "\n",
      "[1000 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "def add_token_count_column(conversation_df):\n",
    "    \"\"\"\n",
    "    Adds a new column to the DataFrame with the token count of the text in the 'text' column.\n",
    "\n",
    "    Args:\n",
    "        conversation_df (pd.DataFrame): A DataFrame containing a 'text' column with string data.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The input DataFrame with an additional column 'token_count',\n",
    "                      containing the number of tokens in each row of the 'text' column.\n",
    "    \"\"\"\n",
    "    # Tokenize the text and count the number of tokens\n",
    "    conversation_df['token_count'] = conversation_df['conv_text'].apply(lambda x: len(str(x).split()))\n",
    "    return conversation_df\n",
    "\n",
    "\n",
    "# Add the token count column\n",
    "conversation_df = add_token_count_column(conversation_df)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(conversation_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conv_id</th>\n",
       "      <th>conv_text</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>satisfaction_rating</th>\n",
       "      <th>token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>USER I'm looking for a cheap restaurant in the...</td>\n",
       "      <td>2.75</td>\n",
       "      <td>Low</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>USER Hi, I will be traveling to Cambridge and ...</td>\n",
       "      <td>2.67</td>\n",
       "      <td>Low</td>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>USER I am looking for a cheap two star hotel i...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Low</td>\n",
       "      <td>313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>USER Can you recommend a good restaurant in th...</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Medium</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>USER I need a place to stay in Cambridge that ...</td>\n",
       "      <td>3.33</td>\n",
       "      <td>Medium</td>\n",
       "      <td>334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>996</td>\n",
       "      <td>USER I'm looking for a cheap hotel.\\nSYSTEM al...</td>\n",
       "      <td>2.75</td>\n",
       "      <td>Low</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>997</td>\n",
       "      <td>USER I'm looking for a Lebanese restaurant tha...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Low</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>998</td>\n",
       "      <td>USER I wanted to visit a place called Center, ...</td>\n",
       "      <td>3.67</td>\n",
       "      <td>High</td>\n",
       "      <td>570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>999</td>\n",
       "      <td>USER Could you help me find a restaurant that'...</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Medium</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1000</td>\n",
       "      <td>USER I want to find a guesthouse to stay at in...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>Low</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     conv_id                                          conv_text  average_rating satisfaction_rating  token_count\n",
       "0          1  USER I'm looking for a cheap restaurant in the...            2.75                 Low          173\n",
       "1          2  USER Hi, I will be traveling to Cambridge and ...            2.67                 Low          468\n",
       "2          3  USER I am looking for a cheap two star hotel i...            3.00                 Low          313\n",
       "3          4  USER Can you recommend a good restaurant in th...            3.50              Medium          219\n",
       "4          5  USER I need a place to stay in Cambridge that ...            3.33              Medium          334\n",
       "..       ...                                                ...             ...                 ...          ...\n",
       "995      996  USER I'm looking for a cheap hotel.\\nSYSTEM al...            2.75                 Low          336\n",
       "996      997  USER I'm looking for a Lebanese restaurant tha...            3.00                 Low          343\n",
       "997      998  USER I wanted to visit a place called Center, ...            3.67                High          570\n",
       "998      999  USER Could you help me find a restaurant that'...            3.50              Medium          287\n",
       "999     1000  USER I want to find a guesthouse to stay at in...            2.00                 Low          162\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_df = pd.read_csv('../data/output/LLM_ingest/conversation_data.csv')\n",
    "conversation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conv_id</th>\n",
       "      <th>conv_text</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>satisfaction_rating</th>\n",
       "      <th>token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>210</td>\n",
       "      <td>USER Hi I am looking for some info on the Wort...</td>\n",
       "      <td>3.67</td>\n",
       "      <td>High</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>301</td>\n",
       "      <td>USER Are there any cheap hotels (not guesthous...</td>\n",
       "      <td>3.67</td>\n",
       "      <td>High</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     conv_id                                          conv_text  average_rating satisfaction_rating  token_count\n",
       "209      210  USER Hi I am looking for some info on the Wort...            3.67                High          151\n",
       "300      301  USER Are there any cheap hotels (not guesthous...            3.67                High          186"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_df[(conversation_df['satisfaction_rating']=='High') & (conversation_df['token_count'] <200)]\n",
    "#210, 301"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conv_id</th>\n",
       "      <th>conv_text</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>satisfaction_rating</th>\n",
       "      <th>token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>301</td>\n",
       "      <td>USER Are there any cheap hotels (not guesthous...</td>\n",
       "      <td>3.67</td>\n",
       "      <td>High</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     conv_id                                          conv_text  average_rating satisfaction_rating  token_count\n",
       "300      301  USER Are there any cheap hotels (not guesthous...            3.67                High          186"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.width', 100000)\n",
    "\n",
    "high_example = conversation_df[conversation_df['conv_id']==301]\n",
    "high_example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(3.6)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_df['average_rating'].quantile([i / 10 for i in range(1, 10)])\n",
    "quantiles = conversation_df['average_rating'].quantile([i / 10 for i in range(1, 10)])\n",
    "quantile_0_3 = quantiles[0.3]\n",
    "quantile_0_9 = quantiles[0.9]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# from nltk.corpus import brown\n",
    "# nltk.download(\"brown\")\n",
    "# # Create a frequency distribution from the Brown corpus\n",
    "# brown_words = brown.words()\n",
    "# freq_dist = nltk.FreqDist(brown_words)\n",
    "\n",
    "# # Define thresholds for rare and common words\n",
    "# common_threshold = 1000  # Common if frequency > 1000\n",
    "# rare_threshold = 10      # Rare if frequency < 10\n",
    "\n",
    "# def calculate_rare_common_ratio(text):\n",
    "#     tokens = text.split()\n",
    "#     rare_count = sum(1 for token in tokens if freq_dist[token.lower()] < rare_threshold)\n",
    "#     common_count = sum(1 for token in tokens if freq_dist[token.lower()] > common_threshold)\n",
    "#     total_count = len(tokens)\n",
    "#     return {\n",
    "#         \"rare_ratio\": rare_count / total_count if total_count else 0,\n",
    "#         \"common_ratio\": common_count / total_count if total_count else 0\n",
    "#     }\n",
    "\n",
    "# # Apply the function to the text column\n",
    "# rare_common_ratios = conversation_df[\"conv_text\"].apply(calculate_rare_common_ratio)\n",
    "# conversation_df[\"rare_ratio\"] = rare_common_ratios.apply(lambda x: x[\"rare_ratio\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: Classify each conversation as 'low', 'medium', or 'high' satisfaction. Here are the conversations:\n",
      "\n",
      "1. \"USER I'm looking for a cheap restaurant in the east part of town.\n",
      "SYSTEM the missing sock is a nice restaurant in the east part of town in the cheap price range\n",
      "USER What is the address and phone number?\n",
      "SYSTEM The address of The Missing Sock is Finders Corner Newmarket Road and the phone number is 01223 812660. May I help you with anything else today?\n",
      "USER Does this restaurant have highchairs for babies?\n",
      "SYSTEM I'm afraid there is no high chair seating available here. You can contact restaurant to see if they will allow you to bring your own.\n",
      "USER Does this restaurant offer delivery services?\n",
      "SYSTEM I'm sorry, they do not offer delivery services. Anything else I can do for you?\n",
      "USER Does The Missing Sock have vegetarian options?\n",
      "SYSTEM No vegetarian options are currently at THE MISSING SOCK. Do you need anything else?\n",
      "USER No, thank you, I have everything I need. Thank you and goodbye!\n",
      "SYSTEM Thank you for using our system. Good bye\n",
      "USER Goodbye.\n",
      "USER OVERALL\"\n",
      "Classification:\n",
      "\n",
      "2. \"USER Hi, I will be traveling to Cambridge and am excited about seeing local tourist attractions.\n",
      "SYSTEM Oh I'm super excited for you! Anything in particular you'd like to check out? How about some architecture?\n",
      "USER Actually, I would prefer a nightclub.\n",
      "SYSTEM There are 5 different nightclubs here in Cambridge. Do you have a specific type in mind?\n",
      "USER No specific type, I just need the area that it's in, please.\n",
      "SYSTEM All nightclubs are located in the centre.\n",
      "USER Thank you. I'm also looking for a hotel in the north with a star of 4.\n",
      "SYSTEM I'm sorry but there are no hotels that meet your criteria. Would you like to try another area?\n",
      "USER Let's try 3 star hotels, instead.\n",
      "SYSTEM still no hotels match your criteria\n",
      "USER Can you check to see if there is a guesthouse available instead of hotel? Something in the North with a star of 4 and free wifi.\n",
      "SYSTEM There are 8 guesthouses in the north with 4 stars and free internet. Are you looking for parking as well?\n",
      "USER No, can you recommend me a good one?\n",
      "SYSTEM The archway house would be a great choice. It's located at 52 gilbert road, cb43pe. Would you like me to try and book a stay for you?\n",
      "USER No thanks. Could you just tell me their phone umber and price range?\n",
      "SYSTEM The archway house's phone number is 01223575314, it's a moderately priced guesthouse. Can I get you any more information?\n",
      "USER I would also like to book a taxi from the Archway House to one of the nightclubs you mentioned. I would like to leave the hotel by 09:45.\n",
      "SYSTEM Certainly. What is your destination?\n",
      "USER Could you recommend a nightclub from the previous search?\n",
      "SYSTEM Yeah, the ballare is great. It's in the centre of town.\n",
      "USER No, I did mean 09:45, thank you.\n",
      "SYSTEM Okay great, the car will be a black honda and the contact number is 07537395912. Is that all you need today?\n",
      "USER Will it be possible to cancel my taxi booking later if my plans change?\n",
      "SYSTEM Sure, you can cancel your taxi reservation without a fee up to 24 hours before your trip. Would you like help finding any other destinations to visit in the evening?\n",
      "USER My plan is not confirmed yet. So I may need to change your taxi booking later. Is that possible for my booking?\n",
      "SYSTEM You can cancel 24 hours in advance. After that only minor changes can be made. Would you like any more assistance?\n",
      "USER Will I be required to pay at the toll gate?\n",
      "SYSTEM No. Toll charges are included in the price. Anything else?\n",
      "USER No, I wanted to check things out during the day time. But thanks for making sure.\n",
      "USER OVERALL\"\n",
      "Classification:\n",
      "\n",
      "3. \"USER I am looking for a cheap two star hotel in the North can you help?\n",
      "SYSTEM Unfortunately, there is nothing available in that area.\n",
      "USER Then can you find a hotel in the west with a moderate price range that includes free wifi?\n",
      "SYSTEM There is nothing like that available either. Would you like to try searching for something else?\n",
      "USER how about one that has free parking?\n",
      "SYSTEM There are two hotels in the west that have free parking. One is in the expensive price range and one is in the cheap range. Which would you prefer?\n",
      "USER I would prefer the cheap range. Can you book for me 8 people for four nights beginning on Friday? I will need the reference number.\n",
      "SYSTEM The booking was successful. Your reference number is : WPCH771U. You will be staying at The Cambridge Belfry in the west area.\n",
      "USER Great, thank you. Can you also help me find something fun for me to do while I am in town?\n",
      "SYSTEM I would suggest visiting the old schools.\n",
      "USER Does the hotel allow children to stay?\n",
      "SYSTEM Yes, the hotel allows customers with children to book rooms there. Do you need any further help?\n",
      "USER Does the hotel offer cooking facilities for guests?\n",
      "SYSTEM The Cambridge Belfry has only a coffee and tea maker for guests at this time. Do you have any other hotel questions?\n",
      "USER Does the hotel have parking facilities?\n",
      "SYSTEM There is free parking available at this location. Would you like any more information?\n",
      "USER Are there any parks around?\n",
      "SYSTEM There are several parks in town. In the centre there's the Cambridge University Botanic Gardens, and a few others in the north, east, and south. Do you have a preference?\n",
      "USER I would it to be in the east and could I get a postcode. Thanks goodbye\n",
      "USER OVERALL\"\n",
      "Classification:\n",
      "\n",
      "4. \"USER Can you recommend a good restaurant in the north part of town that serves Australasian food?\n",
      "SYSTEM There are not restaurants matching your request. May I help you find a different restaurant?\n",
      "USER How about Indian food instead?\n",
      "SYSTEM There are two Indian restaurants in the north part of town. What price range are you looking for?\n",
      "USER What are the price ranges of the two available restaurants?\n",
      "SYSTEM One of them is cheap and the other is moderately price.\n",
      "USER Tell me the address of the moderately priced one.\n",
      "SYSTEM The Nirala is located at 7 Milton Street Chesterton.\n",
      "USER Can you let me know if the Nirala offers any kind of delivery services?\n",
      "SYSTEM The Nirala unfortunately does not deliver. Do you have any other questions about this restaurant?\n",
      "USER Would you be able to tell me if they have chairs for babies to sit in?\n",
      "SYSTEM The Nirala does provide highchairs for babies. Do you need anything else?\n",
      "USER Is there free wifi for dine in customers?\n",
      "SYSTEM Wifi is not shown to be provided. Do you have additional questions about the restaurant?\n",
      "USER What is the phone number?\n",
      "SYSTEM The phone number for the Nirala is 01223 360966. Is there anything else I can help you with?\n",
      "USER No thank you, goodbye\n",
      "USER OVERALL\"\n",
      "Classification:\n",
      "\n",
      "5. \"USER I need a place to stay in Cambridge that includes free wifi. I don't need free parking.\n",
      "SYSTEM Would you like to try cityroomz? I can book it for you?\n",
      "USER Is it in the West? what is the price range?\n",
      "SYSTEM Cityroomz is moderately priced and in the centre. Are you open to places that offer free parking, or do you specifically want to avoid it?\n",
      "USER What is the check-in time at the hotel?\n",
      "SYSTEM You may check in at 13:00 - 1900. What else can I do for you today?\n",
      "USER I'm open to it, and I suppose the centre will do. But I'd prefer the west side if there is one.\n",
      "SYSTEM I'm so sorry. There are no hotels on the west side that match your requests.\n",
      "USER That's okay, Cityroomz will work. Can you book it for 3 people for 2 nights starting on Tuesday?\n",
      "SYSTEM Reference number is : Z9RFJQ4W. Anything else you need?\n",
      "USER Could I get an extra bed in my hotel room?\n",
      "SYSTEM There are no extra beds available there are you looking for anything else? Should I make a reservation for you anyway?\n",
      "USER Yes I am looking for a Train that departs from Cambridge and arrives at Birmingham New Street.\n",
      "SYSTEM Ok. When were you looking to leave?\n",
      "USER I will be leaving on Wednesday after 14:30.\n",
      "SYSTEM There are 9 trains listed. Would you like tickets for one of them?\n",
      "USER Yes. Please select the first train available after 14:30 and book 3 tickets. then provide me the reference number\n",
      "SYSTEM Booking was successful, the total fee is 225.3 GBP payable at the station. Reference number is : XMBOA4E1. Can I help with anything else?\n",
      "USER What are the operating hours of the Cambridge train station?\n",
      "SYSTEM During the week they are open 5AM - 11PM. On Sunday they are open 7AM - 10:55PM. Does that complete my work for you?\n",
      "USER That is all for now. Thank you\n",
      "USER OVERALL\"\n",
      "Classification:\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def create_batch_prompt(batch):\n",
    "    prompt = \"Task: Classify each conversation as 'low', 'medium', or 'high' satisfaction. Here are the conversations:\\n\\n\"\n",
    "    for i, row in enumerate(batch.itertuples(), start=1):\n",
    "        prompt += f\"{i}. \\\"{row.conv_text}\\\"\\nClassification:\\n\\n\"\n",
    "    return prompt\n",
    "\n",
    "# Create prompt for the first 3 rows\n",
    "batch_prompt = create_batch_prompt(conversation_df.head(5))\n",
    "print(batch_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total tokens per conversation = 500 + 50 = 550\n",
    "# Safe batch size = 4096 / 550 â‰ˆ 7 conversations per batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process:\n",
    "* Tiktoken to estimate batch size\n",
    "* When we hit a cutoff, onto the next batch\n",
    "* Parallel thread the batches\n",
    "* Outputs as conversation number. classification\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip show openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[1;32m      2\u001b[0m client \u001b[38;5;241m=\u001b[39m OpenAI()\n\u001b[0;32m----> 4\u001b[0m completion \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4o-mini\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou are a helpful assistant.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWrite a haiku about recursion in programming.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(completion\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage)\n",
      "File \u001b[0;32m~/Desktop/github/convo-quality/myenv/lib/python3.9/site-packages/openai/_utils/_utils.py:275\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/github/convo-quality/myenv/lib/python3.9/site-packages/openai/resources/chat/completions.py:829\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    826\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    827\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    828\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m--> 829\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/github/convo-quality/myenv/lib/python3.9/site-packages/openai/_base_client.py:1278\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1264\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1265\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1266\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1273\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1274\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1275\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1276\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1277\u001b[0m     )\n\u001b[0;32m-> 1278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Desktop/github/convo-quality/myenv/lib/python3.9/site-packages/openai/_base_client.py:955\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    953\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 955\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/github/convo-quality/myenv/lib/python3.9/site-packages/openai/_base_client.py:1044\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1043\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1044\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1047\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1049\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1051\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m~/Desktop/github/convo-quality/myenv/lib/python3.9/site-packages/openai/_base_client.py:1093\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1089\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1090\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1093\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1094\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1098\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/github/convo-quality/myenv/lib/python3.9/site-packages/openai/_base_client.py:1044\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1043\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1044\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1047\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1049\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1051\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m~/Desktop/github/convo-quality/myenv/lib/python3.9/site-packages/openai/_base_client.py:1093\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1089\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1090\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1093\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1094\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1098\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/github/convo-quality/myenv/lib/python3.9/site-packages/openai/_base_client.py:1059\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1056\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1058\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1059\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1062\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1063\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1067\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m   1068\u001b[0m )\n",
      "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Write a haiku about recursion in programming.\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation Error: API error: //github.com/openai/openai-python for the API.\n",
      "\n",
      "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
      "\n",
      "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
      "\n",
      "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "def classify_batch_conversations(batch_prompt, model=\"gpt-3.5-turbo\"):\n",
    "    \"\"\"\n",
    "    Classify conversations from a batch prompt as 'low', 'medium', or 'high' satisfaction.\n",
    "    \n",
    "    Parameters:\n",
    "        batch_prompt (str): The input batch prompt containing multiple conversations.\n",
    "        model (str): The OpenAI model to use for classification (default: \"gpt-3.5-turbo\").\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary with conversation numbers as keys and classification or error reasons as values.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    client = OpenAI()\n",
    "    try:\n",
    "        # Send the entire batch_prompt to the OpenAI API without additional context\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": batch_prompt}\n",
    "            ],\n",
    "            max_tokens=100\n",
    "        )\n",
    "\n",
    "        from openai import OpenAI\n",
    "client = OpenAI()\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"write a haiku about ai\"}\n",
    "    ]\n",
    ")\n",
    "        # response = openai.ChatCompletion.create(\n",
    "        #     model=model,\n",
    "        #     messages=[\n",
    "        #         {\"role\": \"user\", \"content\": batch_prompt}\n",
    "        #     ]\n",
    "        # )\n",
    "        \n",
    "        # Extract the response content\n",
    "        classifications = response[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "        \n",
    "        # Parse the classifications by conversation number\n",
    "        for line in classifications.split(\"\\n\"):\n",
    "            if line.strip():  # Skip empty lines\n",
    "                if \":\" in line:\n",
    "                    convo_number, classification = line.split(\":\", 1)\n",
    "                    convo_number = convo_number.strip()\n",
    "                    classification = classification.strip().lower()\n",
    "                    if classification in [\"low\", \"medium\", \"high\"]:\n",
    "                        results[convo_number] = classification\n",
    "                    else:\n",
    "                        results[convo_number] = f\"Error: Unexpected classification output '{classification}'\"\n",
    "                else:\n",
    "                    # Handle improperly formatted lines\n",
    "                    results[\"Unknown\"] = f\"Error: Malformed response line '{line}'\"\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle any API or parsing errors\n",
    "        results[\"Error\"] = f\"API error: {str(e).split(':', 1)[-1].strip()}\"\n",
    "\n",
    "    return results\n",
    "\n",
    "batch_prompt = create_batch_prompt(conversation_df.head(5))\n",
    "\n",
    "# Call the function\n",
    "results = classify_batch_conversations(batch_prompt, model=\"gpt-3.5-turbo\")\n",
    "for convo, result in results.items():\n",
    "    print(f\"Conversation {convo}: {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_model_costs(conversation_df):\n",
    "#     \"\"\"\n",
    "#     Calculates the cost of processing conversations with GPT-3.5-turbo and Text-Davinci-003\n",
    "#     based on token counts.\n",
    "\n",
    "#     Args:\n",
    "#         conversation_df (pd.DataFrame): A DataFrame with columns:\n",
    "#             - 'conversation_text': The text of the conversation.\n",
    "#             - 'token_count': The number of tokens in the conversation.\n",
    "\n",
    "#     Returns:\n",
    "#         pd.DataFrame: The input DataFrame with two new columns:\n",
    "#             - 'cost_gpt3.5_turbo': The cost for processing the conversation with GPT-3.5-turbo.\n",
    "#             - 'cost_text_davinci_003': The cost for processing the conversation with Text-Davinci-003.\n",
    "#     \"\"\"\n",
    "#     # Define costs per 1,000 tokens\n",
    "#     gpt3_5_turbo_cost_per_1k = 0.0015  # $0.0015 per 1,000 tokens\n",
    "#     text_davinci_003_cost_per_1k = 0.02  # $0.02 per 1,000 tokens\n",
    "\n",
    "#     # Calculate costs\n",
    "#     conversation_df['cost_gpt3.5_turbo'] = (conversation_df['token_count'] / 1000) * gpt3_5_turbo_cost_per_1k\n",
    "#     conversation_df['cost_text_davinci_003'] = (conversation_df['token_count'] / 1000) * text_davinci_003_cost_per_1k\n",
    "\n",
    "#     # Round costs to 4 decimal places for readability\n",
    "#     conversation_df['cost_gpt3.5_turbo'] = conversation_df['cost_gpt3.5_turbo'].round(4)\n",
    "#     conversation_df['cost_text_davinci_003'] = conversation_df['cost_text_davinci_003'].round(4)\n",
    "\n",
    "#     return conversation_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conv_id</th>\n",
       "      <th>conv_text</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>token_count</th>\n",
       "      <th>cost_gpt3.5_turbo</th>\n",
       "      <th>cost_text_davinci_003</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>USER I'm looking for a cheap restaurant in the...</td>\n",
       "      <td>2.75</td>\n",
       "      <td>173</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>USER Hi, I will be traveling to Cambridge and ...</td>\n",
       "      <td>2.67</td>\n",
       "      <td>468</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>USER I am looking for a cheap two star hotel i...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>313</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>USER Can you recommend a good restaurant in th...</td>\n",
       "      <td>3.50</td>\n",
       "      <td>219</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>USER I need a place to stay in Cambridge that ...</td>\n",
       "      <td>3.33</td>\n",
       "      <td>334</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>996</td>\n",
       "      <td>USER I'm looking for a cheap hotel.\\nSYSTEM al...</td>\n",
       "      <td>2.75</td>\n",
       "      <td>336</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>997</td>\n",
       "      <td>USER I'm looking for a Lebanese restaurant tha...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>343</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>998</td>\n",
       "      <td>USER I wanted to visit a place called Center, ...</td>\n",
       "      <td>3.67</td>\n",
       "      <td>570</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>999</td>\n",
       "      <td>USER Could you help me find a restaurant that'...</td>\n",
       "      <td>3.50</td>\n",
       "      <td>287</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1000</td>\n",
       "      <td>USER I want to find a guesthouse to stay at in...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>162</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     conv_id                                          conv_text  average_rating  token_count  cost_gpt3.5_turbo  cost_text_davinci_003\n",
       "0          1  USER I'm looking for a cheap restaurant in the...            2.75          173             0.0003                 0.0035\n",
       "1          2  USER Hi, I will be traveling to Cambridge and ...            2.67          468             0.0007                 0.0094\n",
       "2          3  USER I am looking for a cheap two star hotel i...            3.00          313             0.0005                 0.0063\n",
       "3          4  USER Can you recommend a good restaurant in th...            3.50          219             0.0003                 0.0044\n",
       "4          5  USER I need a place to stay in Cambridge that ...            3.33          334             0.0005                 0.0067\n",
       "..       ...                                                ...             ...          ...                ...                    ...\n",
       "995      996  USER I'm looking for a cheap hotel.\\nSYSTEM al...            2.75          336             0.0005                 0.0067\n",
       "996      997  USER I'm looking for a Lebanese restaurant tha...            3.00          343             0.0005                 0.0069\n",
       "997      998  USER I wanted to visit a place called Center, ...            3.67          570             0.0009                 0.0114\n",
       "998      999  USER Could you help me find a restaurant that'...            3.50          287             0.0004                 0.0057\n",
       "999     1000  USER I want to find a guesthouse to stay at in...            2.00          162             0.0002                 0.0032\n",
       "\n",
       "[1000 rows x 6 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_df = calculate_model_costs(conversation_df)\n",
    "conversation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
